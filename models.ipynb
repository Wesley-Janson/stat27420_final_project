{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Wesley Janson and Drew Keller\n",
    "## STAT 27420 Final Project\n",
    "# Modeling Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load in relevant packages\n",
    "\n",
    "import pandas as pd\n",
    "from statsmodels.miscmodels.ordinal_model import OrderedModel\n",
    "from sklearn.model_selection import KFold, StratifiedKFold, train_test_split\n",
    "from sklearn import tree\n",
    "from sklearn.metrics import accuracy_score, recall_score, precision_score, f1_score, confusion_matrix\n",
    "import xgboost as xgb\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from data_utils import read_data, prep_features, evaluate_predictions\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# set random seed for numpy\n",
    "RANDOM_SEED=69\n",
    "np.random.seed(RANDOM_SEED)\n",
    "\n",
    "\n",
    "DATA_PATH = '../paper_replication_data/new_data.csv'  # Drew's path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Excluding 2262 observations that did not answer 1 year price change question.\n"
     ]
    }
   ],
   "source": [
    "from load_data import data, categorical_vars, cts_vars, other_vars\n",
    "\n",
    "# loading data from online takes ~20 seconds\n",
    "# to speed up, save data locally and load from there:\n",
    "\n",
    "#data.to_csv(DATA_PATH,index=False)  # run this once"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Categorical_vars and cts_vars are lists of vars in each category.\n",
    "# Other_vars are ID and date variables (categorical_vars + cts_vars + other_vars = all vars)\n",
    "\n",
    "data = read_data(DATA_PATH)  # use this over pd.read_csv, because this handles types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0-5      210475\n",
       "5-10      47431\n",
       "NaN       24168\n",
       "10-15     11780\n",
       "20+        5376\n",
       "15-20      4984\n",
       "Name: treatment_bins, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.treatment_bins.value_counts(dropna=False)  # check that we have a balanced dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Good          204553\n",
       "Bad            71471\n",
       "Neutral        12945\n",
       "Don't know     12599\n",
       "Refused         2646\n",
       "Name: durable_purchase, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.durable_purchase.value_counts(dropna=False)  # check that we have a balanced dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Regression***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Excluding 15245 observations that refused or didn't know durable purchase question.\n",
      "Excluding 102089 observations that did not answer confounder questions.\n",
      "Excluding 10354 observations that did not answer price change amount question.\n"
     ]
    }
   ],
   "source": [
    "# prep features for modeling; use regression=True for regression models\n",
    "data_regression, treatment_vars, confounder_vars = prep_features(data,regression=True,missing_values='drop')  \n",
    "X = data_regression[confounder_vars+[\"price_change_amt_next_yr\"]]\n",
    "Y = data_regression['durable_purchase']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.2, random_state=7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.643999\n",
      "         Iterations: 142\n",
      "         Function evaluations: 143\n",
      "         Gradient evaluations: 143\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OrderedModel Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>     <td>durable_purchase</td>  <th>  Log-Likelihood:    </th> <td> -90946.</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>               <td>OrderedModel</td>    <th>  AIC:               </th> <td>1.820e+05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>           <td>Maximum Likelihood</td> <th>  BIC:               </th> <td>1.823e+05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>              <td>Sat, 03 Dec 2022</td>  <th>                     </th>     <td> </td>    \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                  <td>19:41:48</td>      <th>                     </th>     <td> </td>    \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>       <td>141220</td>       <th>                     </th>     <td> </td>    \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>           <td>141186</td>       <th>                     </th>     <td> </td>    \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>               <td>    34</td>       <th>                     </th>     <td> </td>    \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "                    <td></td>                      <th>coef</th>     <th>std err</th>      <th>z</th>      <th>P>|z|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>fed_funds_rate</th>                       <td>    0.2261</td> <td>    0.007</td> <td>   34.525</td> <td> 0.000</td> <td>    0.213</td> <td>    0.239</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>unemployment_rate</th>                    <td>   -0.1477</td> <td>    0.005</td> <td>  -32.673</td> <td> 0.000</td> <td>   -0.157</td> <td>   -0.139</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>cpi_1mo_lag</th>                          <td>   -0.1669</td> <td>    0.007</td> <td>  -24.916</td> <td> 0.000</td> <td>   -0.180</td> <td>   -0.154</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>cpi_durable_1mo_lag</th>                  <td>   -0.1476</td> <td>    0.006</td> <td>  -25.611</td> <td> 0.000</td> <td>   -0.159</td> <td>   -0.136</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>personal_finances_next_yr_Don't know</th> <td>   -0.1829</td> <td>    0.029</td> <td>   -6.303</td> <td> 0.000</td> <td>   -0.240</td> <td>   -0.126</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>personal_finances_next_yr_Refused</th>    <td>   -0.2138</td> <td>    0.069</td> <td>   -3.111</td> <td> 0.002</td> <td>   -0.348</td> <td>   -0.079</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>personal_finances_next_yr_Same</th>       <td>   -0.0482</td> <td>    0.008</td> <td>   -5.821</td> <td> 0.000</td> <td>   -0.064</td> <td>   -0.032</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>personal_finances_next_yr_Worse</th>      <td>   -0.1618</td> <td>    0.013</td> <td>  -12.489</td> <td> 0.000</td> <td>   -0.187</td> <td>   -0.136</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>income_change_amt_next_yr</th>            <td>   -0.0277</td> <td>    0.004</td> <td>   -7.104</td> <td> 0.000</td> <td>   -0.035</td> <td>   -0.020</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>conditions_next_yr_Don't know</th>        <td>   -0.1279</td> <td>    0.036</td> <td>   -3.552</td> <td> 0.000</td> <td>   -0.198</td> <td>   -0.057</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>conditions_next_yr_Refused</th>           <td>   -0.1049</td> <td>    0.070</td> <td>   -1.506</td> <td> 0.132</td> <td>   -0.241</td> <td>    0.032</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>conditions_next_yr_Same</th>              <td>   -0.0309</td> <td>    0.009</td> <td>   -3.394</td> <td> 0.001</td> <td>   -0.049</td> <td>   -0.013</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>conditions_next_yr_Worse</th>             <td>   -0.2289</td> <td>    0.012</td> <td>  -19.427</td> <td> 0.000</td> <td>   -0.252</td> <td>   -0.206</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>unemployment_next_yr_Higher</th>          <td>   -0.2251</td> <td>    0.062</td> <td>   -3.615</td> <td> 0.000</td> <td>   -0.347</td> <td>   -0.103</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>unemployment_next_yr_Lower</th>           <td>    0.0673</td> <td>    0.063</td> <td>    1.076</td> <td> 0.282</td> <td>   -0.055</td> <td>    0.190</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>unemployment_next_yr_Refused</th>         <td>    0.0502</td> <td>    0.123</td> <td>    0.407</td> <td> 0.684</td> <td>   -0.192</td> <td>    0.292</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>unemployment_next_yr_Same</th>            <td>    0.0218</td> <td>    0.062</td> <td>    0.351</td> <td> 0.726</td> <td>   -0.100</td> <td>    0.144</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>income_quintile_Lower middle</th>         <td>   -0.1070</td> <td>    0.012</td> <td>   -8.830</td> <td> 0.000</td> <td>   -0.131</td> <td>   -0.083</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>income_quintile_Lowest</th>               <td>   -0.2043</td> <td>    0.014</td> <td>  -14.823</td> <td> 0.000</td> <td>   -0.231</td> <td>   -0.177</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>income_quintile_Middle</th>               <td>   -0.0777</td> <td>    0.011</td> <td>   -6.877</td> <td> 0.000</td> <td>   -0.100</td> <td>   -0.056</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>income_quintile_Upper middle</th>         <td>   -0.0515</td> <td>    0.010</td> <td>   -4.915</td> <td> 0.000</td> <td>   -0.072</td> <td>   -0.031</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>age</th>                                  <td>   -0.0064</td> <td>    0.004</td> <td>   -1.518</td> <td> 0.129</td> <td>   -0.015</td> <td>    0.002</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>sex_Male</th>                             <td>    0.1101</td> <td>    0.007</td> <td>   14.740</td> <td> 0.000</td> <td>    0.095</td> <td>    0.125</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>education_Graduate school</th>            <td>   -0.0210</td> <td>    0.012</td> <td>   -1.787</td> <td> 0.074</td> <td>   -0.044</td> <td>    0.002</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>education_High school</th>                <td>    0.0295</td> <td>    0.011</td> <td>    2.754</td> <td> 0.006</td> <td>    0.009</td> <td>    0.051</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>education_No high school</th>             <td>   -0.1461</td> <td>    0.027</td> <td>   -5.471</td> <td> 0.000</td> <td>   -0.198</td> <td>   -0.094</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>education_Partial high school</th>        <td>   -0.0188</td> <td>    0.019</td> <td>   -0.987</td> <td> 0.324</td> <td>   -0.056</td> <td>    0.019</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>education_Some college</th>               <td>    0.0215</td> <td>    0.010</td> <td>    2.059</td> <td> 0.040</td> <td>    0.001</td> <td>    0.042</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>household_size</th>                       <td>   -0.0383</td> <td>    0.004</td> <td>   -9.651</td> <td> 0.000</td> <td>   -0.046</td> <td>   -0.030</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>price_related_yr_ago_1.0</th>             <td>   -0.1649</td> <td>    0.010</td> <td>  -16.043</td> <td> 0.000</td> <td>   -0.185</td> <td>   -0.145</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>zlb_1.0</th>                              <td>   -0.0420</td> <td>    0.014</td> <td>   -3.049</td> <td> 0.002</td> <td>   -0.069</td> <td>   -0.015</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>price_change_amt_next_yr</th>             <td>   -0.0283</td> <td>    0.004</td> <td>   -7.685</td> <td> 0.000</td> <td>   -0.036</td> <td>   -0.021</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>-1.0/0.0</th>                             <td>   -0.9712</td> <td>    0.063</td> <td>  -15.375</td> <td> 0.000</td> <td>   -1.095</td> <td>   -0.847</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>0.0/1.0</th>                              <td>   -2.0801</td> <td>    0.014</td> <td> -152.818</td> <td> 0.000</td> <td>   -2.107</td> <td>   -2.053</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                             OrderedModel Results                             \n",
       "==============================================================================\n",
       "Dep. Variable:       durable_purchase   Log-Likelihood:                -90946.\n",
       "Model:                   OrderedModel   AIC:                         1.820e+05\n",
       "Method:            Maximum Likelihood   BIC:                         1.823e+05\n",
       "Date:                Sat, 03 Dec 2022                                         \n",
       "Time:                        19:41:48                                         \n",
       "No. Observations:              141220                                         \n",
       "Df Residuals:                  141186                                         \n",
       "Df Model:                          34                                         \n",
       "========================================================================================================\n",
       "                                           coef    std err          z      P>|z|      [0.025      0.975]\n",
       "--------------------------------------------------------------------------------------------------------\n",
       "fed_funds_rate                           0.2261      0.007     34.525      0.000       0.213       0.239\n",
       "unemployment_rate                       -0.1477      0.005    -32.673      0.000      -0.157      -0.139\n",
       "cpi_1mo_lag                             -0.1669      0.007    -24.916      0.000      -0.180      -0.154\n",
       "cpi_durable_1mo_lag                     -0.1476      0.006    -25.611      0.000      -0.159      -0.136\n",
       "personal_finances_next_yr_Don't know    -0.1829      0.029     -6.303      0.000      -0.240      -0.126\n",
       "personal_finances_next_yr_Refused       -0.2138      0.069     -3.111      0.002      -0.348      -0.079\n",
       "personal_finances_next_yr_Same          -0.0482      0.008     -5.821      0.000      -0.064      -0.032\n",
       "personal_finances_next_yr_Worse         -0.1618      0.013    -12.489      0.000      -0.187      -0.136\n",
       "income_change_amt_next_yr               -0.0277      0.004     -7.104      0.000      -0.035      -0.020\n",
       "conditions_next_yr_Don't know           -0.1279      0.036     -3.552      0.000      -0.198      -0.057\n",
       "conditions_next_yr_Refused              -0.1049      0.070     -1.506      0.132      -0.241       0.032\n",
       "conditions_next_yr_Same                 -0.0309      0.009     -3.394      0.001      -0.049      -0.013\n",
       "conditions_next_yr_Worse                -0.2289      0.012    -19.427      0.000      -0.252      -0.206\n",
       "unemployment_next_yr_Higher             -0.2251      0.062     -3.615      0.000      -0.347      -0.103\n",
       "unemployment_next_yr_Lower               0.0673      0.063      1.076      0.282      -0.055       0.190\n",
       "unemployment_next_yr_Refused             0.0502      0.123      0.407      0.684      -0.192       0.292\n",
       "unemployment_next_yr_Same                0.0218      0.062      0.351      0.726      -0.100       0.144\n",
       "income_quintile_Lower middle            -0.1070      0.012     -8.830      0.000      -0.131      -0.083\n",
       "income_quintile_Lowest                  -0.2043      0.014    -14.823      0.000      -0.231      -0.177\n",
       "income_quintile_Middle                  -0.0777      0.011     -6.877      0.000      -0.100      -0.056\n",
       "income_quintile_Upper middle            -0.0515      0.010     -4.915      0.000      -0.072      -0.031\n",
       "age                                     -0.0064      0.004     -1.518      0.129      -0.015       0.002\n",
       "sex_Male                                 0.1101      0.007     14.740      0.000       0.095       0.125\n",
       "education_Graduate school               -0.0210      0.012     -1.787      0.074      -0.044       0.002\n",
       "education_High school                    0.0295      0.011      2.754      0.006       0.009       0.051\n",
       "education_No high school                -0.1461      0.027     -5.471      0.000      -0.198      -0.094\n",
       "education_Partial high school           -0.0188      0.019     -0.987      0.324      -0.056       0.019\n",
       "education_Some college                   0.0215      0.010      2.059      0.040       0.001       0.042\n",
       "household_size                          -0.0383      0.004     -9.651      0.000      -0.046      -0.030\n",
       "price_related_yr_ago_1.0                -0.1649      0.010    -16.043      0.000      -0.185      -0.145\n",
       "zlb_1.0                                 -0.0420      0.014     -3.049      0.002      -0.069      -0.015\n",
       "price_change_amt_next_yr                -0.0283      0.004     -7.685      0.000      -0.036      -0.021\n",
       "-1.0/0.0                                -0.9712      0.063    -15.375      0.000      -1.095      -0.847\n",
       "0.0/1.0                                 -2.0801      0.014   -152.818      0.000      -2.107      -2.053\n",
       "========================================================================================================\n",
       "\"\"\""
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Model 1a: ordered probit (same as Bachmann et al.) with cts treatment\n",
    "mod_prob1a = OrderedModel(y_train,X_train,distr='probit')\n",
    "res_prob1a = mod_prob1a.fit(method='bfgs')\n",
    "res_prob1a.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline accuracy: 73.73%\n",
      "Train accuracy: 73.79%\n",
      "Test accuracy: 74.13%\n",
      "\n",
      "Test predictions vs actual:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "actual  predicted\n",
       "-1.0    -1             978\n",
       "         1            7015\n",
       " 0.0    -1              84\n",
       "         1            1199\n",
       " 1.0    -1             836\n",
       "         1           25194\n",
       "dtype: int64"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate_predictions(res_prob1a, X_train, X_test, y_train, y_test, regression=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data_regression[confounder_vars+treatment_vars]\n",
    "Y = data_regression['durable_purchase']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.2, random_state=7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.643949\n",
      "         Iterations: 153\n",
      "         Function evaluations: 154\n",
      "         Gradient evaluations: 154\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OrderedModel Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>     <td>durable_purchase</td>  <th>  Log-Likelihood:    </th> <td> -90938.</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>               <td>OrderedModel</td>    <th>  AIC:               </th> <td>1.820e+05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>           <td>Maximum Likelihood</td> <th>  BIC:               </th> <td>1.823e+05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>              <td>Sat, 03 Dec 2022</td>  <th>                     </th>     <td> </td>    \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                  <td>19:29:01</td>      <th>                     </th>     <td> </td>    \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>       <td>141220</td>       <th>                     </th>     <td> </td>    \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>           <td>141182</td>       <th>                     </th>     <td> </td>    \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>               <td>    38</td>       <th>                     </th>     <td> </td>    \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "                    <td></td>                      <th>coef</th>     <th>std err</th>      <th>z</th>      <th>P>|z|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>fed_funds_rate</th>                       <td>    0.2265</td> <td>    0.007</td> <td>   34.597</td> <td> 0.000</td> <td>    0.214</td> <td>    0.239</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>unemployment_rate</th>                    <td>   -0.1470</td> <td>    0.005</td> <td>  -32.509</td> <td> 0.000</td> <td>   -0.156</td> <td>   -0.138</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>cpi_1mo_lag</th>                          <td>   -0.1652</td> <td>    0.007</td> <td>  -24.577</td> <td> 0.000</td> <td>   -0.178</td> <td>   -0.152</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>cpi_durable_1mo_lag</th>                  <td>   -0.1478</td> <td>    0.006</td> <td>  -25.638</td> <td> 0.000</td> <td>   -0.159</td> <td>   -0.137</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>personal_finances_next_yr_Don't know</th> <td>   -0.1825</td> <td>    0.029</td> <td>   -6.288</td> <td> 0.000</td> <td>   -0.239</td> <td>   -0.126</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>personal_finances_next_yr_Refused</th>    <td>   -0.2161</td> <td>    0.069</td> <td>   -3.147</td> <td> 0.002</td> <td>   -0.351</td> <td>   -0.082</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>personal_finances_next_yr_Same</th>       <td>   -0.0487</td> <td>    0.008</td> <td>   -5.875</td> <td> 0.000</td> <td>   -0.065</td> <td>   -0.032</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>personal_finances_next_yr_Worse</th>      <td>   -0.1621</td> <td>    0.013</td> <td>  -12.516</td> <td> 0.000</td> <td>   -0.188</td> <td>   -0.137</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>income_change_amt_next_yr</th>            <td>   -0.0277</td> <td>    0.004</td> <td>   -7.121</td> <td> 0.000</td> <td>   -0.035</td> <td>   -0.020</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>conditions_next_yr_Don't know</th>        <td>   -0.1279</td> <td>    0.036</td> <td>   -3.551</td> <td> 0.000</td> <td>   -0.198</td> <td>   -0.057</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>conditions_next_yr_Refused</th>           <td>   -0.1047</td> <td>    0.070</td> <td>   -1.502</td> <td> 0.133</td> <td>   -0.241</td> <td>    0.032</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>conditions_next_yr_Same</th>              <td>   -0.0312</td> <td>    0.009</td> <td>   -3.432</td> <td> 0.001</td> <td>   -0.049</td> <td>   -0.013</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>conditions_next_yr_Worse</th>             <td>   -0.2287</td> <td>    0.012</td> <td>  -19.413</td> <td> 0.000</td> <td>   -0.252</td> <td>   -0.206</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>unemployment_next_yr_Higher</th>          <td>   -0.2237</td> <td>    0.062</td> <td>   -3.591</td> <td> 0.000</td> <td>   -0.346</td> <td>   -0.102</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>unemployment_next_yr_Lower</th>           <td>    0.0683</td> <td>    0.063</td> <td>    1.093</td> <td> 0.274</td> <td>   -0.054</td> <td>    0.191</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>unemployment_next_yr_Refused</th>         <td>    0.0515</td> <td>    0.123</td> <td>    0.417</td> <td> 0.677</td> <td>   -0.190</td> <td>    0.293</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>unemployment_next_yr_Same</th>            <td>    0.0225</td> <td>    0.062</td> <td>    0.362</td> <td> 0.717</td> <td>   -0.099</td> <td>    0.144</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>income_quintile_Lower middle</th>         <td>   -0.1072</td> <td>    0.012</td> <td>   -8.845</td> <td> 0.000</td> <td>   -0.131</td> <td>   -0.083</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>income_quintile_Lowest</th>               <td>   -0.2039</td> <td>    0.014</td> <td>  -14.800</td> <td> 0.000</td> <td>   -0.231</td> <td>   -0.177</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>income_quintile_Middle</th>               <td>   -0.0778</td> <td>    0.011</td> <td>   -6.886</td> <td> 0.000</td> <td>   -0.100</td> <td>   -0.056</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>income_quintile_Upper middle</th>         <td>   -0.0516</td> <td>    0.010</td> <td>   -4.929</td> <td> 0.000</td> <td>   -0.072</td> <td>   -0.031</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>age</th>                                  <td>   -0.0061</td> <td>    0.004</td> <td>   -1.442</td> <td> 0.149</td> <td>   -0.014</td> <td>    0.002</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>sex_Male</th>                             <td>    0.1112</td> <td>    0.007</td> <td>   14.878</td> <td> 0.000</td> <td>    0.097</td> <td>    0.126</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>education_Graduate school</th>            <td>   -0.0210</td> <td>    0.012</td> <td>   -1.784</td> <td> 0.074</td> <td>   -0.044</td> <td>    0.002</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>education_High school</th>                <td>    0.0294</td> <td>    0.011</td> <td>    2.736</td> <td> 0.006</td> <td>    0.008</td> <td>    0.050</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>education_No high school</th>             <td>   -0.1480</td> <td>    0.027</td> <td>   -5.541</td> <td> 0.000</td> <td>   -0.200</td> <td>   -0.096</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>education_Partial high school</th>        <td>   -0.0209</td> <td>    0.019</td> <td>   -1.097</td> <td> 0.272</td> <td>   -0.058</td> <td>    0.016</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>education_Some college</th>               <td>    0.0219</td> <td>    0.010</td> <td>    2.089</td> <td> 0.037</td> <td>    0.001</td> <td>    0.042</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>household_size</th>                       <td>   -0.0384</td> <td>    0.004</td> <td>   -9.676</td> <td> 0.000</td> <td>   -0.046</td> <td>   -0.031</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>price_related_yr_ago_1.0</th>             <td>   -0.1648</td> <td>    0.010</td> <td>  -16.027</td> <td> 0.000</td> <td>   -0.185</td> <td>   -0.145</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>zlb_1.0</th>                              <td>   -0.0409</td> <td>    0.014</td> <td>   -2.970</td> <td> 0.003</td> <td>   -0.068</td> <td>   -0.014</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>treatment_bins_10-15</th>                 <td>   -0.0886</td> <td>    0.019</td> <td>   -4.589</td> <td> 0.000</td> <td>   -0.126</td> <td>   -0.051</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>treatment_bins_15-20</th>                 <td>   -0.0534</td> <td>    0.029</td> <td>   -1.853</td> <td> 0.064</td> <td>   -0.110</td> <td>    0.003</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>treatment_bins_20+</th>                   <td>   -0.1180</td> <td>    0.029</td> <td>   -4.079</td> <td> 0.000</td> <td>   -0.175</td> <td>   -0.061</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>treatment_bins_5-10</th>                  <td>   -0.0720</td> <td>    0.010</td> <td>   -7.037</td> <td> 0.000</td> <td>   -0.092</td> <td>   -0.052</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>treatment_bins_Missing</th>               <td>         0</td> <td> 2.97e+06</td> <td>        0</td> <td> 1.000</td> <td>-5.81e+06</td> <td> 5.81e+06</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>-1.0/0.0</th>                             <td>   -0.9865</td> <td>    0.063</td> <td>  -15.610</td> <td> 0.000</td> <td>   -1.110</td> <td>   -0.863</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>0.0/1.0</th>                              <td>   -2.0800</td> <td>    0.014</td> <td> -152.811</td> <td> 0.000</td> <td>   -2.107</td> <td>   -2.053</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                             OrderedModel Results                             \n",
       "==============================================================================\n",
       "Dep. Variable:       durable_purchase   Log-Likelihood:                -90938.\n",
       "Model:                   OrderedModel   AIC:                         1.820e+05\n",
       "Method:            Maximum Likelihood   BIC:                         1.823e+05\n",
       "Date:                Sat, 03 Dec 2022                                         \n",
       "Time:                        19:29:01                                         \n",
       "No. Observations:              141220                                         \n",
       "Df Residuals:                  141182                                         \n",
       "Df Model:                          38                                         \n",
       "========================================================================================================\n",
       "                                           coef    std err          z      P>|z|      [0.025      0.975]\n",
       "--------------------------------------------------------------------------------------------------------\n",
       "fed_funds_rate                           0.2265      0.007     34.597      0.000       0.214       0.239\n",
       "unemployment_rate                       -0.1470      0.005    -32.509      0.000      -0.156      -0.138\n",
       "cpi_1mo_lag                             -0.1652      0.007    -24.577      0.000      -0.178      -0.152\n",
       "cpi_durable_1mo_lag                     -0.1478      0.006    -25.638      0.000      -0.159      -0.137\n",
       "personal_finances_next_yr_Don't know    -0.1825      0.029     -6.288      0.000      -0.239      -0.126\n",
       "personal_finances_next_yr_Refused       -0.2161      0.069     -3.147      0.002      -0.351      -0.082\n",
       "personal_finances_next_yr_Same          -0.0487      0.008     -5.875      0.000      -0.065      -0.032\n",
       "personal_finances_next_yr_Worse         -0.1621      0.013    -12.516      0.000      -0.188      -0.137\n",
       "income_change_amt_next_yr               -0.0277      0.004     -7.121      0.000      -0.035      -0.020\n",
       "conditions_next_yr_Don't know           -0.1279      0.036     -3.551      0.000      -0.198      -0.057\n",
       "conditions_next_yr_Refused              -0.1047      0.070     -1.502      0.133      -0.241       0.032\n",
       "conditions_next_yr_Same                 -0.0312      0.009     -3.432      0.001      -0.049      -0.013\n",
       "conditions_next_yr_Worse                -0.2287      0.012    -19.413      0.000      -0.252      -0.206\n",
       "unemployment_next_yr_Higher             -0.2237      0.062     -3.591      0.000      -0.346      -0.102\n",
       "unemployment_next_yr_Lower               0.0683      0.063      1.093      0.274      -0.054       0.191\n",
       "unemployment_next_yr_Refused             0.0515      0.123      0.417      0.677      -0.190       0.293\n",
       "unemployment_next_yr_Same                0.0225      0.062      0.362      0.717      -0.099       0.144\n",
       "income_quintile_Lower middle            -0.1072      0.012     -8.845      0.000      -0.131      -0.083\n",
       "income_quintile_Lowest                  -0.2039      0.014    -14.800      0.000      -0.231      -0.177\n",
       "income_quintile_Middle                  -0.0778      0.011     -6.886      0.000      -0.100      -0.056\n",
       "income_quintile_Upper middle            -0.0516      0.010     -4.929      0.000      -0.072      -0.031\n",
       "age                                     -0.0061      0.004     -1.442      0.149      -0.014       0.002\n",
       "sex_Male                                 0.1112      0.007     14.878      0.000       0.097       0.126\n",
       "education_Graduate school               -0.0210      0.012     -1.784      0.074      -0.044       0.002\n",
       "education_High school                    0.0294      0.011      2.736      0.006       0.008       0.050\n",
       "education_No high school                -0.1480      0.027     -5.541      0.000      -0.200      -0.096\n",
       "education_Partial high school           -0.0209      0.019     -1.097      0.272      -0.058       0.016\n",
       "education_Some college                   0.0219      0.010      2.089      0.037       0.001       0.042\n",
       "household_size                          -0.0384      0.004     -9.676      0.000      -0.046      -0.031\n",
       "price_related_yr_ago_1.0                -0.1648      0.010    -16.027      0.000      -0.185      -0.145\n",
       "zlb_1.0                                 -0.0409      0.014     -2.970      0.003      -0.068      -0.014\n",
       "treatment_bins_10-15                    -0.0886      0.019     -4.589      0.000      -0.126      -0.051\n",
       "treatment_bins_15-20                    -0.0534      0.029     -1.853      0.064      -0.110       0.003\n",
       "treatment_bins_20+                      -0.1180      0.029     -4.079      0.000      -0.175      -0.061\n",
       "treatment_bins_5-10                     -0.0720      0.010     -7.037      0.000      -0.092      -0.052\n",
       "treatment_bins_Missing                        0   2.97e+06          0      1.000   -5.81e+06    5.81e+06\n",
       "-1.0/0.0                                -0.9865      0.063    -15.610      0.000      -1.110      -0.863\n",
       "0.0/1.0                                 -2.0800      0.014   -152.811      0.000      -2.107      -2.053\n",
       "========================================================================================================\n",
       "\"\"\""
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Model 1b: ordered probit (same as Bachmann et al.) with cts treatment\n",
    "mod_prob1b = OrderedModel(y_train,X_train,distr='probit')\n",
    "res_prob1b = mod_prob1b.fit(method='bfgs')\n",
    "res_prob1b.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline accuracy: 73.73%\n",
      "Train accuracy: 73.80%\n",
      "Test accuracy: 74.08%\n",
      "\n",
      "Test predictions vs actual:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "actual  predicted\n",
       "-1.0    -1             971\n",
       "         1            7022\n",
       " 0.0    -1              86\n",
       "         1            1197\n",
       " 1.0    -1             848\n",
       "         1           25182\n",
       "dtype: int64"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate_predictions(res_prob1b, X_train, X_test, y_train, y_test, regression=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Classification with XGBoost***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Excluding 12029 observations that refused or didn't know durable purchase question.\n",
      "Excluding 16763 observations that did not answer price change amount question.\n"
     ]
    }
   ],
   "source": [
    "data_xgboost, treatment_vars, confounder_vars = prep_features(data,regression=False,missing_values='retain')  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "Can only use .dt accessor with datetimelike values",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [4], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39m# only income_change_amt_next_yr has many missing values within our chosen cts confounders\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \n\u001b[1;32m      3\u001b[0m \u001b[39m# calculate percent missing for income_change_amt_next_yr by year \u001b[39;00m\n\u001b[0;32m----> 4\u001b[0m pct_missing \u001b[39m=\u001b[39m data[\u001b[39m'\u001b[39m\u001b[39mincome_change_amt_next_yr\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m.\u001b[39misnull()\u001b[39m.\u001b[39mgroupby(data\u001b[39m.\u001b[39mdate\u001b[39m.\u001b[39mdt\u001b[39m.\u001b[39myear)\u001b[39m.\u001b[39magg([\u001b[39m'\u001b[39m\u001b[39mmean\u001b[39m\u001b[39m'\u001b[39m,\u001b[39m'\u001b[39m\u001b[39mcount\u001b[39m\u001b[39m'\u001b[39m])\n\u001b[1;32m      5\u001b[0m plt\u001b[39m.\u001b[39mplot(pct_missing[\u001b[39m\"\u001b[39m\u001b[39mmean\u001b[39m\u001b[39m\"\u001b[39m])\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/pandas/core/generic.py:5907\u001b[0m, in \u001b[0;36mNDFrame.__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   5900\u001b[0m \u001b[39mif\u001b[39;00m (\n\u001b[1;32m   5901\u001b[0m     name \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_internal_names_set\n\u001b[1;32m   5902\u001b[0m     \u001b[39mand\u001b[39;00m name \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_metadata\n\u001b[1;32m   5903\u001b[0m     \u001b[39mand\u001b[39;00m name \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_accessors\n\u001b[1;32m   5904\u001b[0m     \u001b[39mand\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_info_axis\u001b[39m.\u001b[39m_can_hold_identifiers_and_holds_name(name)\n\u001b[1;32m   5905\u001b[0m ):\n\u001b[1;32m   5906\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m[name]\n\u001b[0;32m-> 5907\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mobject\u001b[39;49m\u001b[39m.\u001b[39;49m\u001b[39m__getattribute__\u001b[39;49m(\u001b[39mself\u001b[39;49m, name)\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/pandas/core/accessor.py:183\u001b[0m, in \u001b[0;36mCachedAccessor.__get__\u001b[0;34m(self, obj, cls)\u001b[0m\n\u001b[1;32m    180\u001b[0m \u001b[39mif\u001b[39;00m obj \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    181\u001b[0m     \u001b[39m# we're accessing the attribute of the class, i.e., Dataset.geo\u001b[39;00m\n\u001b[1;32m    182\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_accessor\n\u001b[0;32m--> 183\u001b[0m accessor_obj \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_accessor(obj)\n\u001b[1;32m    184\u001b[0m \u001b[39m# Replace the property with the accessor object. Inspired by:\u001b[39;00m\n\u001b[1;32m    185\u001b[0m \u001b[39m# https://www.pydanny.com/cached-property.html\u001b[39;00m\n\u001b[1;32m    186\u001b[0m \u001b[39m# We need to use object.__setattr__ because we overwrite __setattr__ on\u001b[39;00m\n\u001b[1;32m    187\u001b[0m \u001b[39m# NDFrame\u001b[39;00m\n\u001b[1;32m    188\u001b[0m \u001b[39mobject\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__setattr__\u001b[39m(obj, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_name, accessor_obj)\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/pandas/core/indexes/accessors.py:513\u001b[0m, in \u001b[0;36mCombinedDatetimelikeProperties.__new__\u001b[0;34m(cls, data)\u001b[0m\n\u001b[1;32m    510\u001b[0m \u001b[39melif\u001b[39;00m is_period_dtype(data\u001b[39m.\u001b[39mdtype):\n\u001b[1;32m    511\u001b[0m     \u001b[39mreturn\u001b[39;00m PeriodProperties(data, orig)\n\u001b[0;32m--> 513\u001b[0m \u001b[39mraise\u001b[39;00m \u001b[39mAttributeError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mCan only use .dt accessor with datetimelike values\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "\u001b[0;31mAttributeError\u001b[0m: Can only use .dt accessor with datetimelike values"
     ]
    }
   ],
   "source": [
    "# only income_change_amt_next_yr has many missing values within our chosen cts confounders\n",
    "\n",
    "# calculate percent missing for income_change_amt_next_yr by year \n",
    "pct_missing = data['income_change_amt_next_yr'].isnull().groupby(data.date.dt.year).agg(['mean','count'])\n",
    "plt.plot(pct_missing[\"mean\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Excluding 12029 observations that refused or didn't know durable purchase question.\n",
      "Imputing 60221 missing values for income_change_amt_next_yr with median.\n",
      "Imputing 1346 missing values for age with median.\n",
      "Imputing 467 missing values for household_size with median.\n",
      "Excluding 16763 observations that did not answer price change amount question.\n"
     ]
    }
   ],
   "source": [
    "data_xgboost, treatment_vars, confounder_vars = prep_features(data,regression=False,missing_values='impute by median')  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>XGBClassifier(base_score=0.5, booster=&#x27;gbtree&#x27;, callbacks=None,\n",
       "              colsample_bylevel=1, colsample_bynode=1, colsample_bytree=1,\n",
       "              early_stopping_rounds=None, enable_categorical=False,\n",
       "              eval_metric=None, feature_types=None, gamma=0, gpu_id=-1,\n",
       "              grow_policy=&#x27;depthwise&#x27;, importance_type=None,\n",
       "              interaction_constraints=&#x27;&#x27;, learning_rate=0.300000012,\n",
       "              max_bin=256, max_cat_threshold=64, max_cat_to_onehot=4,\n",
       "              max_delta_step=0, max_depth=6, max_leaves=0, min_child_weight=1,\n",
       "              missing=nan, monotone_constraints=&#x27;()&#x27;, n_estimators=100,\n",
       "              n_jobs=0, num_parallel_tree=1, objective=&#x27;multi:softprob&#x27;,\n",
       "              predictor=&#x27;auto&#x27;, ...)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">XGBClassifier</label><div class=\"sk-toggleable__content\"><pre>XGBClassifier(base_score=0.5, booster=&#x27;gbtree&#x27;, callbacks=None,\n",
       "              colsample_bylevel=1, colsample_bynode=1, colsample_bytree=1,\n",
       "              early_stopping_rounds=None, enable_categorical=False,\n",
       "              eval_metric=None, feature_types=None, gamma=0, gpu_id=-1,\n",
       "              grow_policy=&#x27;depthwise&#x27;, importance_type=None,\n",
       "              interaction_constraints=&#x27;&#x27;, learning_rate=0.300000012,\n",
       "              max_bin=256, max_cat_threshold=64, max_cat_to_onehot=4,\n",
       "              max_delta_step=0, max_depth=6, max_leaves=0, min_child_weight=1,\n",
       "              missing=nan, monotone_constraints=&#x27;()&#x27;, n_estimators=100,\n",
       "              n_jobs=0, num_parallel_tree=1, objective=&#x27;multi:softprob&#x27;,\n",
       "              predictor=&#x27;auto&#x27;, ...)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', callbacks=None,\n",
       "              colsample_bylevel=1, colsample_bynode=1, colsample_bytree=1,\n",
       "              early_stopping_rounds=None, enable_categorical=False,\n",
       "              eval_metric=None, feature_types=None, gamma=0, gpu_id=-1,\n",
       "              grow_policy='depthwise', importance_type=None,\n",
       "              interaction_constraints='', learning_rate=0.300000012,\n",
       "              max_bin=256, max_cat_threshold=64, max_cat_to_onehot=4,\n",
       "              max_delta_step=0, max_depth=6, max_leaves=0, min_child_weight=1,\n",
       "              missing=nan, monotone_constraints='()', n_estimators=100,\n",
       "              n_jobs=0, num_parallel_tree=1, objective='multi:softprob',\n",
       "              predictor='auto', ...)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Model 2: XGBoost with binned treatment\n",
    "\n",
    "X = data_xgboost[confounder_vars+treatment_vars]\n",
    "Y = data_xgboost['durable_purchase']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.2, random_state=7)\n",
    "model2 = xgb.XGBClassifier()\n",
    "model2.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline accuracy: 73.88%\n",
      "Train accuracy: 76.86%\n",
      "Test accuracy: 74.66%\n",
      "\n",
      "Test predictions vs actual:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "actual  predicted\n",
       "0.0     0             1637\n",
       "        1                3\n",
       "        2             8140\n",
       "1.0     0              114\n",
       "        2             1521\n",
       "2.0     0             1290\n",
       "        1                5\n",
       "        2            30989\n",
       "dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate_predictions(model2, X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Classification with NN***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model 3: large neural network just to see if we can overfit at least\n",
    "model3 = MLPClassifier(hidden_layer_sizes=(100,100), max_iter=1000)\n",
    "model3.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15603"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_params = sum([coef.shape[0] * coef.shape[1] for coef in model3.coefs_])\n",
    "num_params += sum([intercept.shape[0] for intercept in model3.intercepts_])\n",
    "num_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline accuracy: 71.63%\n",
      "Train accuracy: 76.52%\n",
      "Test accuracy: 70.52%\n",
      "\n",
      "Test predictions vs actual:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "actual  predicted\n",
       "0.0     0             3076\n",
       "        1              109\n",
       "        2             9738\n",
       "1.0     0              307\n",
       "        1               30\n",
       "        2             1916\n",
       "2.0     0             3495\n",
       "        1              206\n",
       "        2            34619\n",
       "dtype: int64"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate_predictions(model3, X_train, X_test, y_train, y_test,regression=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Conditional outcome models (Q models)\n",
    "def make_Q_model():\n",
    "    ''' A function that returns a general ML q model for later use in k-folding'''\n",
    "    return xgb.XGBRegressor()\n",
    "\n",
    "# Propensity score models (g models)\n",
    "def make_g_model():\n",
    "    ''' A function that returns a g model for computing propensity scores'''\n",
    "    return xgb.XGBClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Functions for K-fold cross-fitting\n",
    "def treatment_k_fold_fit_and_predict(make_model, X:pd.DataFrame, A:np.array, n_splits:int):\n",
    "    '''\n",
    "    Implements K fold cross-fitting for the model predicting the treatment A. \n",
    "    That is, \n",
    "    1. Split data into K folds\n",
    "    2. For each fold j, the model is fit on the other K-1 folds\n",
    "    3. The fitted model is used to make predictions for each data point in fold j\n",
    "    Returns an array containing the predictions  \n",
    "\n",
    "    Args:\n",
    "    model: function that returns sklearn model (which implements fit and predict_prob)\n",
    "    X: dataframe of variables to adjust for\n",
    "    A: array of treatments\n",
    "    n_splits: number of splits to use\n",
    "    '''\n",
    "\n",
    "    predictions = np.full_like(A, np.nan, dtype=float)\n",
    "    kf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=RANDOM_SEED)\n",
    "    \n",
    "    for train_index, test_index in kf.split(X, A):\n",
    "        X_train = X.loc[train_index]\n",
    "        A_train = A.loc[train_index]\n",
    "        g = make_model()\n",
    "        g.fit(X_train, A_train)\n",
    "\n",
    "        # get predictions for split\n",
    "        predictions[test_index] = g.predict_proba(X.loc[test_index])[:, 1]\n",
    "    \n",
    "    # sanity check that overlap holds\n",
    "    assert np.isnan(predictions).sum() == 0\n",
    "    return predictions\n",
    "\n",
    "def outcome_k_fold_fit_and_predict(make_model, X:pd.DataFrame, y:np.array, A:np.array, n_splits:int, output_type:str):\n",
    "    '''\n",
    "    Implements K fold cross-fitting for the model predicting the outcome Y. \n",
    "    That is, \n",
    "    1. Split data into K folds\n",
    "    2. For each fold j, the model is fit on the other K-1 folds\n",
    "    3. The fitted model is used to make predictions for each data point in fold j\n",
    "    Returns two arrays containing the predictions for all units untreated, all units treated  \n",
    "\n",
    "    Args:\n",
    "    model: function that returns sklearn model (that implements fit and either predict_prob or predict)\n",
    "    X: dataframe of variables to adjust for\n",
    "    y: array of outcomes\n",
    "    A: array of treatments\n",
    "    n_splits: number of splits to use\n",
    "    output_type: type of outcome, \"binary\" or \"continuous\"\n",
    "    '''\n",
    "\n",
    "    predictions0 = np.full_like(A, np.nan, dtype=float)\n",
    "    predictions1 = np.full_like(y, np.nan, dtype=float)\n",
    "    if output_type == 'binary':\n",
    "        kf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=RANDOM_SEED)\n",
    "    elif output_type == 'continuous':\n",
    "        kf = KFold(n_splits=n_splits, shuffle=True, random_state=RANDOM_SEED)\n",
    "\n",
    "    # include the treatment as input feature\n",
    "    X_w_treatment = X.copy()\n",
    "    X_w_treatment[\"A\"] = A\n",
    "\n",
    "    # for predicting effect under treatment / control status for each data point \n",
    "    X0 = X_w_treatment.copy()\n",
    "    X0[\"A\"] = 0\n",
    "    X1 = X_w_treatment.copy()\n",
    "    X1[\"A\"] = 1\n",
    "    X2 = X_w_treatment.copy()\n",
    "    X2[\"A\"] = 2\n",
    "    X3 = X_w_treatment.copy()\n",
    "    X3[\"A\"] = 3\n",
    "    X4 = X_w_treatment.copy()\n",
    "    X4[\"A\"] = 4\n",
    "\n",
    "    \n",
    "    for train_index, test_index in kf.split(X_w_treatment, y):\n",
    "        X_train = X_w_treatment.loc[train_index]\n",
    "        y_train = y.loc[train_index]\n",
    "        q = make_model()\n",
    "        q.fit(X_train, y_train)\n",
    "\n",
    "        if output_type =='binary':\n",
    "            predictions0[test_index] = q.predict_proba(X0.loc[test_index])[:, 1]\n",
    "            predictions1[test_index] = q.predict_proba(X1.loc[test_index])[:, 1]\n",
    "        elif output_type == 'continuous':\n",
    "            predictions0[test_index] = q.predict(X0.loc[test_index])\n",
    "            predictions1[test_index] = q.predict(X1.loc[test_index])\n",
    "\n",
    "\n",
    "    assert np.isnan(predictions0).sum() == 0\n",
    "    assert np.isnan(predictions1).sum() == 0\n",
    "    return predictions0, predictions1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit single Q() model\n",
    "# get conditional outcomes\n",
    "Q0_lm, Q1_lm = outcome_k_fold_fit_and_predict(make_Q_model, X=confounders, y=outcome, A=treatment, \\\n",
    "                                        n_splits=5, output_type=\"continuous\")\n",
    "\n",
    "# Fir 4 g(x) models\n",
    "g1 = treatment_k_fold_fit_and_predict(make_g_model, X=confounders, A=treatment, n_splits=5)\n",
    "g2 = treatment_k_fold_fit_and_predict(make_g_model, X=confounders, A=treatment, n_splits=5)\n",
    "g3 = treatment_k_fold_fit_and_predict(make_g_model, X=confounders, A=treatment, n_splits=5)\n",
    "g4 = treatment_k_fold_fit_and_predict(make_g_model, X=confounders, A=treatment, n_splits=5)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.6 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
